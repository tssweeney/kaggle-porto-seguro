{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"kaggle_comp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"sub.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"load.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"scoring.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Exploration\n",
    "\n",
    "The [Porto Sequro](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) Kaggle Competition is centered around predicting the likelihood that an insured driver/car pair is going to submit a claim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Format\n",
    "The features have all been anonymized and conform to the following naming convention: `ps_CAT_##[_TYPE]`.\n",
    "\n",
    "`CAT` refers to one of the following categories:\n",
    " - `ind` - I assume to mean general \"indicator\"\n",
    " - `reg` - I assume to mean insurance \"registrant\"\n",
    " - `car` - I assume to mean \"car\"\n",
    " - `calc` - I assume to mean \"calculated\" field\n",
    "\n",
    "`##` refers to the feature number within the category\n",
    "\n",
    "`TYPE` is optional and refers to one of the following type:\n",
    " - ` ` - No type indicates a scalar\n",
    " - `cat` - Indicates a categorical feature\n",
    " - `bin` - Indicates a binary feature\n",
    "    \n",
    "All missing values are indicated by a `-1`\n",
    "\n",
    "There is an `id` column used to mark the id of the entry.\n",
    "The training data has a `target` column that is the target value (binary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scoring\n",
    "This particular competition uses the `normalized gini coefficient` for scoring. [Wikipedia](https://en.wikipedia.org/wiki/Gini_coefficient) has a mind-numbing explaination. What is important is that you are measuring the ORDERING of the results, not the predicted value. This score ranges from 0.0 to 1.0. For scoring The magnitude of the prediction does not matter, only the order. For example, lets say you have 4 observations (shown with their targets) in perfect order:\n",
    " - A - 1\n",
    " - B - 1\n",
    " - C - 0\n",
    " - D - 0\n",
    " \n",
    "Ordering ABCD gets a perfect score of 1.0. However, let's say you have the following order (shown with predictions):\n",
    " - B - 0.9 (1)\n",
    " - C - 0.4 (0)\n",
    " - A - 0.3 (1)\n",
    " - D - 0.1 (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You calculate the gini coefficient by:\n",
    " - summing the cummulative actual values\n",
    "  - `(1) + (1 + 0) + (1 + 0 + 1) + (1 + 0 + 1 + 0) = 6`\n",
    " - divide by the total number of positive targets\n",
    "  - `6 / 2 = 3`\n",
    " - subtracting half of 1 plus the length\n",
    "  - `3 - (4 + 1) / 2 = 3 - 2.5 = 0.5`\n",
    " - dividing by the length\n",
    "  - `0.5 / 4 = 0.125`\n",
    "\n",
    "To find the normalized score, divide this value by the perfect gini score for the set:\n",
    "\n",
    " - `(1) + (1 + 1) + (1 + 1 + 0) + (1 + 1 + 0 + 0) = 8`\n",
    " - `8 / 2 = 4`\n",
    " - `4 - (4 + 1) / 2 = 4 - 2.5 = 1.5`\n",
    " - `1.5 / 4 = 0.375`\n",
    " - `0.125 / 0.375 = 0.5`\n",
    "\n",
    "If all of this was confusing, think of it as the \"shuffle factor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Thinking about scoring is important. At first glance this looks like a classification problem. However, predicting only 1 or 0 would leave ties to random ordering creating horrible results. In a way, this is regression. However, regression is not optimal because your RSME is usually large since the values are either 1 or 0. So, using classifiers, but pulling out the class probability was the best approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Data Import\n",
    "df_train = pd.read_csv(\"../input/train.csv\")\n",
    "df_test = pd.read_csv(\"../input/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print(\"train.csv null value count = \" + str(df_train.isnull().sum().sum()))\n",
    "print(\"train.csv -1 value count = \" + str((df_train == -1).sum().sum()))\n",
    "print(\"test.csv null value count = \" + str(df_test.isnull().sum().sum()))\n",
    "print(\"test.csv -1 value count = \" + str((df_test == -1).sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def data_density(df):\n",
    "    print(\"Number of rows = \" + str(df.shape[0]))\n",
    "    print(\"Number of columns = \" + str(df.shape[1]))\n",
    "    print(\"null value count = \" + str(df.isnull().sum().sum()))\n",
    "    neg_1_count = (df == -1).sum().sum()\n",
    "    print(\"-1 value count = \" + str(neg_1_count) + \"(\"+str(100. * neg_1_count / df.shape[0] / df.shape[1])+\"%)\")\n",
    "    num_sparce_rows = ((df == -1).T.sum() > 0).sum()\n",
    "    print(\"Number of sparce rows = \" + str(num_sparce_rows) + \"(\"+str(100. * num_sparce_rows /  df.shape[0])+\"%)\")\n",
    "    num_sparce_cols = ((df == -1).sum() > 0).sum()\n",
    "    print(\"Number of sparce columns = \" + str(num_sparce_cols) + \"(\"+str(100. * num_sparce_cols / df.shape[1])+\"%)\")\n",
    "\n",
    "    print(\"\")\n",
    "    densities = (df != -1).sum() / df.shape[0]\n",
    "    print(\"Columns with less than 100% density:\")\n",
    "    print(densities[densities < 1] * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Train.csv density analysis:\")\n",
    "data_density(df_train)\n",
    "print(\"\")\n",
    "print(\"Test.csv density analysis:\")\n",
    "data_density(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Columns Analysis\n",
    "res_cols = [\"id\",  \"target\"]\n",
    "bin_cols = [col for col in df_train.columns if col[-3:] == \"bin\"]\n",
    "cat_cols = [col for col in df_train.columns if col[-3:] == \"cat\"]\n",
    "num_cols = [col for col in df_train.columns if col not in res_cols + bin_cols + cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Standard Heatmap\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sns.heatmap(df_train.corr(), linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# heatmap of non-binary columns\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sns.heatmap(df_train[cat_cols + num_cols + [\"target\"]].corr(), linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Bin variable analysis\n",
    "df_bin = df_train[[\"target\"] + bin_cols]\n",
    "df_temp = df_bin.groupby(\"target\").mean()\n",
    "df_temp = df_temp.append(df_bin[bin_cols].mean(), ignore_index=True).append(df_bin[bin_cols].std(), ignore_index=True).T\n",
    "df_temp.columns = [\"0_mean\", \"1_mean\", \"mean\", \"std\"]\n",
    "df_temp[\"0_std_dev\"] = (df_temp[\"0_mean\"] - df_temp[\"mean\"]) / df_temp[\"std\"]\n",
    "df_temp[\"1_std_dev\"] = (df_temp[\"1_mean\"] - df_temp[\"mean\"]) / df_temp[\"std\"]\n",
    "df_temp[\"std_dev_diff\"] = df_temp[\"0_std_dev\"] - df_temp[\"1_std_dev\"]\n",
    "df_temp[\"std_dev_diff\"] = df_temp[\"std_dev_diff\"].abs()\n",
    "df_temp.sort_values(\"std_dev_diff\", ascending=False)\n",
    "\n",
    "# We are interested in seeing if the binary variables are skewed in any direction.\n",
    "# If they were, then we would see that the std_dev for 0 or 1 would signifantly differ\n",
    "# In fact, we do see this in some (ps_ind_17_bin, ps_ind_07_bin, ps_ind_06_bin)\n",
    "# However, this difference is relatively small and unlikely to discriminate well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_bin.groupby(\"target\").var().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's build a binary tree!\n",
    "# I made this up... not much interesting here\n",
    "\n",
    "mean_target = df_bin[\"target\"].mean()\n",
    "bin_tree = df_bin.groupby(bin_cols).agg([lambda x: math.sqrt(((np.array(x) - mean_target)**2).mean()), \"mean\", \"count\"]).reset_index()\n",
    "bin_tree.columns = bin_tree.columns.get_level_values(0)[0:-3].tolist()  + [\"rsme\", \"mean\", \"count\"]\n",
    "min_count = df_bin.shape[0] / bin_tree.shape[0]\n",
    "bin_tree[bin_tree[\"count\"] >= min_count].sort_values(\"rsme\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Ok, let's take a look at the numeric fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Define some helper functions to describe / plot columns\n",
    "\n",
    "def column_details(df, col, is_cat=False):\n",
    "    print(\"(\"+col+\") Null Values: \" + str(df[col].isnull().sum()))\n",
    "    print(df[col].describe())\n",
    "    if is_cat:\n",
    "        sns.countplot(y=col, data=df)\n",
    "    else:\n",
    "        sns.distplot(df[col][np.logical_not(df[col].isnull())], kde=False)\n",
    "        \n",
    "    plt.show()\n",
    "    \n",
    "def data_details(data, num_cols, cat_cols):\n",
    "    for col in num_cols:\n",
    "        column_details(data, col)\n",
    "    \n",
    "    for col in cat_cols:\n",
    "        column_details(data, col, is_cat=True)\n",
    "\n",
    "    for col in bin_cols:\n",
    "        column_details(data, col, is_cat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data_details(df_train, num_cols, bin_cols + cat_cols + [\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for col in df_train.columns:\n",
    "    sns.jointplot(x=col, y=\"target\", data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
